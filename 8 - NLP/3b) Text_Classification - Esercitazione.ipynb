{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a32f50df",
   "metadata": {},
   "source": [
    "## Riscriviamo le funzioni per il data cleaning e il bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab0adc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "english_stopwords = stopwords.words('english')\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "punctuation = set(string.punctuation)\n",
    "\n",
    "def data_cleaner(dataset):\n",
    "    dataset_to_return = []\n",
    "    for sentence in dataset:\n",
    "        sentence = sentence.lower()\n",
    "        for c in string.punctuation:\n",
    "            sentence = sentence.replace(c, \" \")\n",
    "        document = nlp(sentence)\n",
    "        sentence = ' '.join(token.lemma_ for token in document)\n",
    "        sentence = ' '.join(word for word in sentence.split() if word not in english_stopwords)\n",
    "        sentence = re.sub('\\d', '', sentence)\n",
    "        dataset_to_return.append(sentence)\n",
    "\n",
    "    return dataset_to_return\n",
    "\n",
    "\n",
    "def bow_tfidf(dataset, tfidf_vectorizer):\n",
    "    if tfidf_vectorizer == None:\n",
    "        tfidf_vectorizer = TfidfVectorizer()\n",
    "        X = tfidf_vectorizer.fit_transform(dataset)\n",
    "    else:\n",
    "        X = tfidf_vectorizer.transform(dataset)\n",
    "        \n",
    "    return X.toarray(), tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2806cc92",
   "metadata": {},
   "source": [
    "## Importiamo i dataset di training e test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fc20e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "training_dataset = fetch_20newsgroups(subset='train')\n",
    "test_dataset = fetch_20newsgroups(subset='test')\n",
    "training_data = training_dataset['data']\n",
    "training_target = training_dataset['target']\n",
    "test_data = test_dataset['data']\n",
    "test_target = test_dataset['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a9e9405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(training_dataset['target_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18beae08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(test_dataset['target_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "892a0081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f5a15d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7532"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa3cf78",
   "metadata": {},
   "source": [
    "## Preprocessing dei due dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac95b4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_cleaned, tfidf_vectorizer = bow_tfidf(data_cleaner(training_data), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18594b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_cleaned, tfidf_vectorizer = bow_tfidf(data_cleaner(test_data), tfidf_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88a1c561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58f2b507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85861"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data_cleaned[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0157d4a",
   "metadata": {},
   "source": [
    "## Training del modello MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20233eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.96068117\n",
      "Iteration 2, loss = 2.84575317\n",
      "Iteration 3, loss = 2.70571062\n",
      "Iteration 4, loss = 2.50874556\n",
      "Iteration 5, loss = 2.24233564\n",
      "Iteration 6, loss = 1.92176401\n",
      "Iteration 7, loss = 1.58873002\n",
      "Iteration 8, loss = 1.28436972\n",
      "Iteration 9, loss = 1.03004214\n",
      "Iteration 10, loss = 0.82739668\n",
      "Iteration 11, loss = 0.66974385\n",
      "Iteration 12, loss = 0.54951430\n",
      "Iteration 13, loss = 0.45605936\n",
      "Iteration 14, loss = 0.38382021\n",
      "Iteration 15, loss = 0.32750966\n",
      "Iteration 16, loss = 0.28284630\n",
      "Iteration 17, loss = 0.24756801\n",
      "Iteration 18, loss = 0.21853918\n",
      "Iteration 19, loss = 0.19496381\n",
      "Iteration 20, loss = 0.17553189\n",
      "Iteration 21, loss = 0.15933475\n",
      "Iteration 22, loss = 0.14560792\n",
      "Iteration 23, loss = 0.13416534\n",
      "Iteration 24, loss = 0.12439207\n",
      "Iteration 25, loss = 0.11591883\n",
      "Iteration 26, loss = 0.10869069\n",
      "Iteration 27, loss = 0.10241793\n",
      "Iteration 28, loss = 0.09691251\n",
      "Iteration 29, loss = 0.09214376\n",
      "Iteration 30, loss = 0.08789092\n",
      "Iteration 31, loss = 0.08414793\n",
      "Iteration 32, loss = 0.08080306\n",
      "Iteration 33, loss = 0.07785169\n",
      "Iteration 34, loss = 0.07510739\n",
      "Iteration 35, loss = 0.07269587\n",
      "Iteration 36, loss = 0.07050615\n",
      "Iteration 37, loss = 0.06843139\n",
      "Iteration 38, loss = 0.06663496\n",
      "Iteration 39, loss = 0.06496308\n",
      "Training loss did not improve more than tol=0.005000 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', max_iter=100, tol=0.005, verbose=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(activation='logistic',\n",
    "                    hidden_layer_sizes=(100,),\n",
    "                    max_iter=100,\n",
    "                    solver='adam',\n",
    "                    tol=0.005,\n",
    "                    verbose=True)\n",
    "\n",
    "clf.fit(training_data_cleaned,training_target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048b8f20",
   "metadata": {},
   "source": [
    "## Testiamo il modello "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "573c557e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.856744556558683"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(test_data_cleaned, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6d8d7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = clf.predict(bow_tfidf(data_cleaner([\"This is a mac book pro!!!\"]),tfidf_vectorizer)[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd905b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55ebe4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'comp.sys.mac.hardware'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset['target_names'][target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed9cc28d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From: v064mb9k@ubvmsd.cc.buffalo.edu (NEIL B. GANDLER)\\nSubject: Need info on 88-89 Bonneville\\nOrganization: University at Buffalo\\nLines: 10\\nNews-Software: VAX/VMS VNEWS 1.41\\nNntp-Posting-Host: ubvmsd.cc.buffalo.edu\\n\\n\\n I am a little confused on all of the models of the 88-89 bonnevilles.\\nI have heard of the LE SE LSE SSE SSEI. Could someone tell me the\\ndifferences are far as features or performance. I am also curious to\\nknow what the book value is for prefereably the 89 model. And how much\\nless than book value can you usually get them for. In other words how\\nmuch are they in demand this time of year. I have heard that the mid-spring\\nearly summer is the best time to buy.\\n\\n\\t\\t\\tNeil Gandler\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "711a4d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sci.electronics'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset['target_names'][clf.predict([test_data_cleaned[0]])[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0b65a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rec.autos'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset['target_names'][test_target[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39e123e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From: Rick Miller <rick@ee.uwm.edu>\\nSubject: X-Face?\\nOrganization: Just me.\\nLines: 17\\nDistribution: world\\nNNTP-Posting-Host: 129.89.2.33\\nSummary: Go ahead... swamp me.  <EEP!>\\n\\nI\\'m not familiar at all with the format of these \"X-Face:\" thingies, but\\nafter seeing them in some folks\\' headers, I\\'ve *got* to *see* them (and\\nmaybe make one of my own)!\\n\\nI\\'ve got \"dpg-view\" on my Linux box (which displays \"uncompressed X-Faces\")\\nand I\\'ve managed to compile [un]compface too... but now that I\\'m *looking*\\nfor them, I can\\'t seem to find any X-Face:\\'s in anyones news headers!  :-(\\n\\nCould you, would you, please send me your \"X-Face:\" header?\\n\\nI *know* I\\'ll probably get a little swamped, but I can handle it.\\n\\n\\t...I hope.\\n\\nRick Miller  <rick@ee.uwm.edu> | <ricxjo@discus.mil.wi.us>   Ricxjo Muelisto\\nSend a postcard, get one back! | Enposxtigu bildkarton kaj vi ricevos alion!\\n          RICK MILLER // 16203 WOODS // MUSKEGO, WIS. 53150 // USA\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36c740fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Subject: help\\nFrom: C..Doelle@p26.f3333.n106.z1.fidonet.org (C. Doelle)\\nLines: 13\\n\\nHello All!\\n\\n    It is my understanding that all True-Type fonts in Windows are loaded in\\nprior to starting Windows - this makes getting into Windows quite slow if you\\nhave hundreds of them as I do.  First off, am I correct in this thinking -\\nsecondly, if that is the case - can you get Windows to ignore them on boot and\\nmaybe make something like a PIF file to load them only when you enter the\\napplications that need fonts?  Any ideas?\\n\\n\\nChris\\n\\n * Origin: chris.doelle.@f3333.n106.z1.fidonet.org (1:106/3333.26)\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "401f3bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'comp.os.ms-windows.misc'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset['target_names'][clf.predict([test_data_cleaned[100]])[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b90ebf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'comp.os.ms-windows.misc'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset['target_names'][test_target[100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3435cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
